# Data Analysis and Engineering Portfolio for LDOE

## Overview
Welcome to my professional portfolio, showcasing a range of projects that highlight my skills in both data analysis and data engineering. Developed for the Louisiana Department of Education (LDOE), these projects demonstrate my expertise in data processing, analysis, and engineering, using advanced technologies like Polars and DuckDB.

### Disclaimer
The contents of this repository are for demonstration and portfolio purposes only. The code and methodologies are proprietary and not available for reuse or distribution.

## Projects

### ACT Match/No Match
- **Objective**: Demonstrates my skills in data analysis and engineering through the matching and identification of records in large datasets using Polars.
- **Technologies Used**: 
  - Python for data processing and analysis.
  - Polars for efficient data manipulation and analysis.
  - JSON for configuration management.
- **Highlights**:
  - Development of efficient algorithms for data matching.
  - Implementation of data preprocessing and cleaning, showcasing data engineering techniques.
- **Files**:
  - [Main Script](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/ACT_match_nomatch/main.py)
  - [Configuration](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/ACT_match_nomatch/config_match_no_match.json)
  - [Utility Functions](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/ACT_match_nomatch/utils.py)
  - [Data Processing Scripts](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/tree/master/ACT_match_nomatch)

### EDEN 178-188
- **Objective**: Showcases my transition into data engineering with a focus on cleaning and formatting large-scale student-level data, utilizing DuckDB and Polars.
- **Technologies Used**: 
  - DuckDB for efficient database operations.
  - Polars for high-performance data manipulation.
  - SQL for data querying and manipulation.
- **Highlights**:
  - Advanced data storage and querying techniques.
  - Efficient data processing and analysis, typical of data engineering roles.
- **Files**:
  - [Main Script](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/EDEN_178_188/main.py)
  - [Data Calculation](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/EDEN_178_188/data_calculation.py)
  - [DuckDB Operations](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/EDEN_178_188/duckdb_operation.py)
  - [SQL Queries](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/EDEN_178_188/student_level_data_cleaning.sql)

### LEAP (Louisiana Educational Assessment Program)
#### LEAP - Original Project (Optimized for Local Machines)
- **Objective**: This original version of the LEAP project demonstrates my proficiency in optimizing data processing on local machines. It utilizes Pandas in combination with multiprocessing/multithreading techniques.
- **Technologies Used**: 
  - **Pandas**: For efficient data manipulation and analysis.
  - **Multiprocessing/Multithreading**: To enhance performance and speed on local machines by parallelizing data processing tasks.
- **Highlights**:
  - Custom implementation of parallel processing techniques to significantly improve the efficiency of data operations in Pandas.
  - Tailored for scenarios where data processing needs to be optimized for single-machine environments.
  - Effective handling of large datasets with resource-efficient methods.

#### LEAP - Enhanced Version with PySpark (Scalable for Big Data)
- **Objective**: The enhanced version of the LEAP project showcases my skills in handling big data using PySpark, emphasizing scalability and distributed computing.
- **Technologies Used**: 
  - **PySpark**: A powerful tool for big data processing, offering distributed data processing capabilities.
- **Highlights**:
  - Scalable data processing suitable for very large datasets.
  - Utilizing distributed computing to process data faster and more efficiently across clusters.
  - Demonstrates my ability to adapt data processing strategies to different scales and environments, from local machines to big data ecosystems.

#### About this project
The LEAP projects reflect my versatile approach to data processing, showcasing the ability to optimize performance on local machines and scale up for big data challenges. These projects illustrate my adaptability and skill in employing the right tools and techniques to suit the specific needs of the data and the computational environment.
- **Files**:
  - [Data Extraction Tools](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/tree/master/LEAP/Extract_PDF_Data_spark/PDFDataExtractionTools)
  - [Main Script](https://github.com/mag1cfrog/data_anlysis_projects_LDOE/blob/master/LEAP/Extract_PDF_Data_spark/main.py)

## Usage
- Python 3.x is required.
- Additional libraries: Pandas, PySpark, Polars, DuckDB (as per project requirements).

## Contribution
Contributions are welcome! Please fork the repository, create a new branch for your features, and submit a pull request.

## About Me
As a current Data Analyst aspiring to transition into Data Engineering, I am passionate about turning complex data into actionable insights and scalable data solutions. My expertise lies in data processing, analysis, and the use of cutting-edge technologies to handle large and complex datasets.

## Seeking Opportunities
I am actively seeking opportunities that allow me to grow in the field of Data Engineering while leveraging my strong background in Data Analysis. I am open to roles that challenge me and expand my skill set in both areas.

## Contact
For job opportunities, collaborations, or feedback, please feel free to reach out to me:
- Email: [harrywong2017@gmail.com](mailto:harrywong2017@gmail.com)
- LinkedIn: [Hanbo Wang](https://www.linkedin.com/in/hanbo-wang-mag1cfrog/)
